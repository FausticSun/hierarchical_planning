{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a88d1f96",
   "metadata": {},
   "source": [
    "# Using LLMs as High-Level Planners for Multi-Agent Coordination\n",
    "\n",
    "This notebook provides a step-by-step guide to customizing and interacting with the RL environment.\n",
    "\n",
    "## For Submission\n",
    "1. Fill in your code in `submit.py`. \n",
    "   - Add your code *only* in the TODO sections marked by the '#' delimiter lines. Do not modify any other parts of the script.\n",
    "   - You should implement any helper functions/classes in a separate `helper.py` file and import them in `submit.py`.\n",
    "1. Submit `out.log` and `results.csv` generated by the `submit.py` script.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "751f8d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries and modules\n",
    "import gymnasium as gym\n",
    "import multigrid.envs\n",
    "import matplotlib.pyplot as plt\n",
    "from agents import AgentCollection\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb33076",
   "metadata": {},
   "source": [
    "---\n",
    "## Initial Plan Generation\n",
    "\n",
    "An intial plan can be generated by the `initial_planner` by invoking it with the grid size and number of agents available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e48b12f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import claude_llm as llm\n",
    "from planner import PromptPlanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6b8d91a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Search Plan for 10×10 Grid with 2 Agents to Find 2 Targets\n",
      "\n",
      "## Mission Analysis\n",
      "- Grid size: 10×10\n",
      "- Agents: 2 (starting at position (1,1))\n",
      "- Targets: 2 (locations unknown, no specific hints provided)\n",
      "- No additional constraints or probabilistic information given\n",
      "\n",
      "## Strategy Overview\n",
      "Since we have 2 agents and 2 targets in a 10×10 grid with no specific location hints, I'll implement a complete grid coverage strategy by dividing the grid into two equal rectangular regions. With equal-sized regions and no location hints, a simple horizontal split is most efficient.\n",
      "\n",
      "## Region Assignment\n",
      "- **Region 1**: Coordinates (1,1) to (5,10) - Left half of grid (50 cells)\n",
      "- **Region 2**: Coordinates (6,1) to (10,10) - Right half of grid (50 cells)\n",
      "\n",
      "## Agent Plans\n",
      "\n",
      "### Agent 1\n",
      "1. **Start**: Agent is already at (1,1), which is within Region 1\n",
      "2. **Search**: From position (1,1), search the rectangular area from (1,1) to (5,10)\n",
      "\n",
      "### Agent 2\n",
      "1. **Movement**: Move from (1,1) to (6,1) by traveling east 5 steps\n",
      "2. **Search**: From position (6,1), search the rectangular area from (6,1) to (10,10)\n",
      "\n",
      "## Execution Timeline\n",
      "- **Step 1**: \n",
      "  - Agent 1: Search region (1,1) to (5,10) from position (1,1)\n",
      "  - Agent 2: Move from (1,1) to (2,1)\n",
      "\n",
      "- **Step 2**: \n",
      "  - Agent 1: No action (completed)\n",
      "  - Agent 2: Move from (2,1) to (3,1)\n",
      "\n",
      "- **Step 3**: \n",
      "  - Agent 1: No action (completed)\n",
      "  - Agent 2: Move from (3,1) to (4,1)\n",
      "\n",
      "- **Step 4**: \n",
      "  - Agent 1: No action (completed)\n",
      "  - Agent 2: Move from (4,1) to (5,1)\n",
      "\n",
      "- **Step 5**: \n",
      "  - Agent 1: No action (completed)\n",
      "  - Agent 2: Move from (5,1) to (6,1)\n",
      "\n",
      "- **Step 6**: \n",
      "  - Agent 1: No action (completed)\n",
      "  - Agent 2: Search region (6,1) to (10,10) from position (6,1)\n",
      "\n",
      "## Efficiency Analysis\n",
      "- Total steps required: 6\n",
      "- Each agent searches exactly once, covering their entire assigned region\n",
      "- No redundant coverage or overlapping searches\n",
      "- Agent 1 can begin searching immediately while Agent 2 travels to position\n",
      "- Complete grid coverage ensures both targets will be found\n",
      "\n",
      "This plan efficiently divides the grid into two equal regions, minimizes movement, and ensures both targets will be discovered in parallel operations.\n",
      "{0: [SearchAction(type=<ActionType.SEARCH: 'search'>, cur_x=1, cur_y=1, x1=1, y1=1, x2=5, y2=10)], 1: [MoveAction(type=<ActionType.MOVE: 'move'>, cur_x=1, cur_y=1, tar_x=6, tar_y=1), SearchAction(type=<ActionType.SEARCH: 'search'>, cur_x=6, cur_y=1, x1=6, y1=1, x2=10, y2=10)]}\n",
      "{0: {'image': array([[[1, 0, 0]]]), 'direction': np.int64(0), 'mission': Mission(\"All targets are contained within the region from (3, 3) to (5, 5).\"), 'location': (np.int64(2), np.int64(1))}, 1: {'image': array([[[1, 0, 0]]]), 'direction': np.int64(0), 'mission': Mission(\"All targets are contained within the region from (3, 3) to (5, 5).\"), 'location': (np.int64(2), np.int64(1))}, 'global': {'num_goals': 2}}\n",
      "{0: <ActionUpDown.right: 1>, 1: <ActionUpDown.right: 1>} {0: -1, 1: -1} {0: np.False_, 1: np.False_} {0: False, 1: False}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PromptPlanner' object has no attribute 'tracker'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(observations)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(a, rewards, terminations, truncations)\n\u001b[0;32m---> 37\u001b[0m plan \u001b[38;5;241m=\u001b[39m \u001b[43mplanner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43magents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrewards\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mterminations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfos\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent, actions \u001b[38;5;129;01min\u001b[39;00m plan\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m actions:\n",
      "File \u001b[0;32m/mount/home/lwenhan/git/hierarchical_planning/planner/prompt_planner.py:73\u001b[0m, in \u001b[0;36mPromptPlanner.replan\u001b[0;34m(self, agents, observations, rewards, terminations, truncations, infos)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m([r \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rewards\u001b[38;5;241m.\u001b[39mvalues()]):\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# Re-plan when a target is found\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtracker\u001b[49m\u001b[38;5;241m.\u001b[39mobserve(observations, rewards)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {}\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PromptPlanner' object has no attribute 'tracker'"
     ]
    }
   ],
   "source": [
    "N, M = 10, 2\n",
    "env = multigrid.envs.EmptyEnvV2(\n",
    "    size=N,  # Specify the size of the grid, N\n",
    "    agents=M,  # Specify number of agents, M\n",
    "    goals=[(3, 3), (5, 5)],  # Specify target positions for agents\n",
    "    mission_space=\"All targets are contained within the region from (3, 3) to (5, 5).\",\n",
    "    render_mode=\"rgb_array\",\n",
    "    hidden_goals=True,\n",
    "    # max_steps=50, # For debugging, you can set a maximum number of steps\n",
    ")\n",
    "\n",
    "# Always reset the environment before starting\n",
    "observations, infos = env.reset()\n",
    "\n",
    "# Create a group of 2 agents\n",
    "agents = AgentCollection(num=2)\n",
    "\n",
    "planner = PromptPlanner(llm=llm, grid_size=N, observations=observations, infos=infos)\n",
    "\n",
    "# Providing the agents with high-level instructions\n",
    "mission = observations[0][\"mission\"]\n",
    "plan = planner.initial_plan()\n",
    "print(plan)\n",
    "for agent, actions in plan.items():\n",
    "    for action in actions:\n",
    "        agents.tell({agent: action.serialize()})\n",
    "\n",
    "while not agents.all_idle() and not env.unwrapped.is_done():\n",
    "    # Obtain the low-level action for current time step for all agents\n",
    "    a = agents.act()\n",
    "\n",
    "    # Step the environment with the actions\n",
    "    observations, rewards, terminations, truncations, infos = env.step(a)\n",
    "    print(observations)\n",
    "    print(a, rewards, terminations, truncations)\n",
    "\n",
    "    plan = planner.replan(\n",
    "        agents, observations, rewards, terminations, truncations, infos\n",
    "    )\n",
    "    for agent, actions in plan.items():\n",
    "        for action in actions:\n",
    "            agents.tell({agent: action.serialize()})\n",
    "\n",
    "    # Render the environment\n",
    "    img = env.render()\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93081833",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multigrid (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
