# üß≠ LLM-based Multi-Agent Planner

<br/>
<p align="center">
  <img src="https://i.imgur.com/LDeSLDi.gif" width=400 alt="2 Agents with 2 goals">
</p>
<br/>

This is an extension to the [MultiGrid](https://ini.github.io/docs/multigrid) library for hierarchical planning.
<br>

## üíæ Installation

    conda create -n multigoal python=3.10
    conda activate multigoal
    git clone https://github.com/yhchong/hierarchical_planning.git
    cd hierarchical_planning
    pip install -e .

This package requires Python 3.9 or later.
<br>
<br>

## üöÄ Getting Started
1) See `tutorial.ipynb`.

```python
import gymnasium as gym
import multigrid.envs

env = gym.make('MultiGrid-EmptyEnvV2-hidden-20x20-v0', agents=2, render_mode='human')
agents = AgentCollection(num=2)
# this is where you would insert your initial plan from LLM
agents.tell({
    0: "search(1, 1, 10, 10, 15, 5)",
    1: "search(1, 1, 10, 10, 5, 15)"
})

observations, infos = env.reset()
while not env.unwrapped.is_done():
   # this is where you would insert new plans from LLM if necessary 
   actions = agents.act()
   observations, rewards, terminations, truncations, infos = env.step(actions)

env.close()
```
<br>

## üß™ Evaluation Procedure
* A portion of your final score will be based on the **cumulative rewards** obtained in the **test environments**, which will be released at a later stage (see sample: `env_config_example.ini`).
For details on how rewards are defined and used, refer to `tutorial.ipynb:Rewards`.
* Each test environment will be rolled out multiple times, as specified by the `number_of_trials` field in `env_config_example.ini`.
* For each environment:
  * Your submission will be evaluated over the specified number of rollouts.
  * The environment score is computed as the average cumulative reward across these rollouts.
  * The final score will be a weighted average of the scores across all test environments.

<br>
‚ö†Ô∏è Important Constraints

Your method must rely solely on information obtained through interaction with the environment, as specified in tutorial.ipynb.

 * You must not access or extract any information directly from `env_config_example.ini`.
 * This configuration file is used only by the evaluation script and not meant to guide planning or decision-making.
<br>
<br>

## üì§ Submission

1) Fill in your code in `submit.py`.
   * Add your code *only* in the TODO sections marked by the '#' delimiter lines. Do not modify any other parts of the script.
   * You should implement any helper functions/classes in a separate `helper.py` file and import them in `submit.py`.
2) Submit `out.log` and `results.csv` generated by the `submit.py` script.
