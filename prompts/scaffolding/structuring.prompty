---
model:
  api: chat
---
user:
# Context
At each timestep *t*, the environment takes in a dictionary of low-level actions(LLA: left, right, up, down, nothing) for each agent and execute them.

However, for our purpose, we are interested in using LLM to control the agent behavior via the following high-level actions (HLA): 
- `move(cur_x, cur_y, tar_x, tar_y)`\
Instruct an agent to move from its current location (`cur_x`, `cur_y`) to the target coordinate (`tar_x`, `tar_y`).
- `search(cur_x, cur_y, x1, y1, x2, y2)`\
Instruct an agent at current location (`cur_x`, `cur_y`) to search within the rectangular region bounded by (`x1`, `y1`) and (`x2`, `y2`).
The agent will translate this high-level action into movement from (`cur_x`, `cur_y`) to (`x1`, `y1`), then perform the search by moving in a snake-like fashion through the region bounded by (`x1`, `y1`) and (`x2`, `y2`).
- `stop()`\
Instruct the agent to stop all activity and ignore current instructions.

Given a high-level action, an agent will automatically translated it into low-level action sequences. For example,
`move(1, 1, 3, 3)` â†’ [`right`, `right`, `down`, `down`].

IMPT: The high-level actions follow strict formatting. e.g., ensure all the brackets and commas(if applicable) are present. 

# Task
Give a Pydantic v2 model that is able to capture the list of high-level actions for each agent. Assume the agent ID is an integer.
Keep the use of validators to a minimum, use specialized fields or types to perform constraints.
Since I would only know the bounds at runtime, allow for the constraints of the various x and y to be dynamically changed. I want to be able to specify the maximum and minimum of x and y dynamically. Use Annotated to do so.